from requests import get
from bs4 import BeautifulSoup
from hashlib import md5
from time import sleep

# might not even need this
currentLinks = []
currentPost = []
currentCategories = []

payload = {
    'action' : '.xml',
    'type' : 'rss'
}

def hashed(x):
    return md5(x.content).hexdigest()

if __name__ == "__main__":
    print('[+] Checking Top Hat...\n\t[+] Ctrl+C to exit')
    currentCheck = '33cc562fa5964d59de2d21743b3d5c9e'
    try:
        while True:
            response = get('http://forum.top-hat-sec.com/index.php', params=payload) #still need to figure out how to login so we can post in chat
            soup = BeautifulSoup(response.content, 'html.parser')
            if currentCheck == hashed(response):
                print('[+] There are no new posts!')
            else:
                print('[+] There\'s a new post!')
                currentCheck = hashed(response)
            sleep(5) # 5 seconds just a test. will be checking every 15 minutes?
                    # 900 seconds 15 minute checks
    except KeyboardInterrupt:
        print('[!] Exitting...')

# Test code so i wont forget
#for links in soup.findAll('link')[1:]:
#   currentLinks.append(links)
#   if links in currentLinks:
#        print('[+] Click here to view: {}'.format(links.text))
#for posts in soup.findAll('title')[1:]:
#    currentPost.append(posts)
#   if posts in currentPost:
#        print('{}'.format(posts.text))
#for category in soup.findAll('category'):
#    currentCategories.append(category)

#print links, posts, category
